{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export java11 to use\n",
    "import os\n",
    "os.environ['JAVA_HOME'] = '/home/team1/.jdk/jdk-11.0.19+7'\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark\"\n",
    "\n",
    "# import findspark and initialize it\n",
    "import findspark\n",
    "findspark.init(\"/opt/spark\")\n",
    "\n",
    "# Import the sparknlp library and the PretrainedPipeline class\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace, when\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql.types import DoubleType, BooleanType\n",
    "import pyspark.sql.functions as f\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "# start spark nlp session\n",
    "sparknlp.start()\n",
    "\n",
    "# Create a spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SentimentAnalysisPretrained\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"100g\") \\\n",
    "    .config(\"spark.executor.memory\", \"100g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\",\"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\",\"100g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READ DATASET...\n"
     ]
    }
   ],
   "source": [
    "# Load the sentiment data\n",
    "# Assume the data has two columns: body and score\n",
    "# Score is an integer from 1 to 5\n",
    "print('READ DATASET...')\n",
    "data = spark.read.csv('part2_900k.csv', inferSchema=True, header=True, multiLine=True, quote='\"', escape='\"')\n",
    "data = data.select('review/score', (lower(regexp_replace('review/text', \"[^a-zA-Z\\\\s]\", \"\")).alias('review/text')))\n",
    "data = data.dropna()\n",
    "\n",
    "# Convert to 2 label 0, 1\n",
    "data = data.replace(1, 0, subset=[\"review/score\"])\n",
    "data = data.replace(2, 0, subset=[\"review/score\"])\n",
    "data = data.replace(3, 0, subset=[\"review/score\"])\n",
    "data = data.replace(4, 1, subset=[\"review/score\"])\n",
    "data = data.replace(5, 1, subset=[\"review/score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into training and testing sets\n",
    "train_df, test_df = data.randomSplit([0.9, 0.1], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n",
      "sentimentdl_use_imdb download started this may take some time.\n",
      "Approximate size to download 12 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    ".setInputCol(\"review/text\") \\\n",
    ".setOutputCol(\"document\")\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained('tfhub_use', lang=\"en\") \\\n",
    ".setInputCols([\"document\"])\\\n",
    ".setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "classifier = SentimentDLModel().pretrained('sentimentdl_use_imdb')\\\n",
    ".setInputCols([\"sentence_embeddings\"])\\\n",
    ".setOutputCol(\"sentiment\")\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[document_assembler,\n",
    "use,\n",
    "classifier\n",
    "])\n",
    "\n",
    "l_model = LightPipeline(nlp_pipeline.fit(spark.createDataFrame([['']]).toDF(\"review/text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_model.pipeline_model.save('pipelines/pretrained_sentiment_on_imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = l_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review/score: integer (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- sentence_embeddings: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- sentiment: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.select('review/score', 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------------------------------------------------------------------------+\n",
      "|review/score|sentiment                                                                             |\n",
      "+------------+--------------------------------------------------------------------------------------+\n",
      "|0           |[[category, 0, 228, neg, [sentence -> 0, pos -> 2.1157134E-6, neg -> 0.99999785], []]]|\n",
      "|0           |[[category, 0, 554, pos, [sentence -> 0, pos -> 0.99998105, neg -> 1.8939772E-5], []]]|\n",
      "|0           |[[category, 0, 2551, pos, [sentence -> 0, pos -> 0.9999907, neg -> 9.277911E-6], []]] |\n",
      "+------------+--------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictions.withColumn('prediction', f.explode('sentiment.result')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction='pos'), Row(prediction='neg'), Row(prediction='neutral')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('prediction').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review/score: integer (nullable = true)\n",
      " |-- review/text: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- sentence_embeddings: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- sentiment: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = result.replace('neg', '0', subset=['prediction'])\n",
    "result = result.replace('neutral', '0', subset=['prediction'])\n",
    "result = result.replace('pos', '1', subset=['prediction'])\n",
    "\n",
    "result = result.withColumn('prediction', col('prediction').cast('double'))\n",
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+----------+\n",
      "|review/score|           sentiment|prediction|\n",
      "+------------+--------------------+----------+\n",
      "|           0|[{category, 0, 22...|       0.0|\n",
      "|           0|[{category, 0, 55...|       1.0|\n",
      "|           0|[{category, 0, 25...|       1.0|\n",
      "+------------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION...\n",
      "The accuracy of the model is 0.83\n"
     ]
    }
   ],
   "source": [
    "print(\"EVALUATION...\")\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"review/score\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(result)\n",
    "print(f\"The accuracy of the model is {accuracy:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 of the model is 0.82\n"
     ]
    }
   ],
   "source": [
    "evaluator.setMetricName('f1')\n",
    "f1 = evaluator.evaluate(result)\n",
    "print(f\"The f1 of the model is {f1:0.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
